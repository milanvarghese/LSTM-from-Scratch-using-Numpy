{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Poem Dataset:\n",
      "Roses are red,\n",
      "Violets are blue,\n",
      "The sky is clear,\n",
      "And so are you.\n",
      "\n",
      "The moon is bright,\n",
      "The stars do shine,\n",
      "The night is calm,\n",
      "A perfect sign.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the dataset file\n",
    "data_file_path = os.path.join(\"data\", \"data.txt\")\n",
    "\n",
    "# Read the poem dataset\n",
    "with open(data_file_path, \"r\") as file:\n",
    "    poem_text = file.read()\n",
    "\n",
    "print(\"Loaded Poem Dataset:\")\n",
    "print(poem_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_file_path = os.path.join(\"data\", \"data.txt\")\n",
    "with open(data_file_path, \"r\") as file:\n",
    "    poem_text = file.read()\n",
    "words = poem_text.split(\" \")\n",
    "len(words)\n",
    "set_word = set(words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 's ', 'th', 'i', 's ', 'th', 'e ', 'rea', 'l', ' ', 'life ', 'I', 's ', 'th', 'i', 's ', 'just ', 'f', 'an', 't', 'as', 'y\\n', 'C', 'a', 'u', 'ght ', 'in', ' a', ' ', 'l', 'and', 's', 'li', 'd', 'e, ', 'no', ' ', 'es', 'ca', 'p', 'e ', 'from', ' rea', 'li', 't', 'y\\n', 'O', 'p', 'en ', 'your ', 'ey', 'es', ', ', 'lo', 'o', 'k ', 'up', ' to', ' ', 'th', 'e ', 's', 'k', 'i', 'es ', 'and', ' s', 'ee', '\\n', \"I'm just a poor bo\", 'y, ', 'I ', 'n', 'ee', 'd ', 'no', ' s', 'y', 'm', 'p', 'a', 'th', 'y\\n', 'B', 'e', 'ca', 'us', 'e ', \"I'm \", 'easy ', 'come, easy go, ', 'little ', 'hi', 'gh', ', ', 'little ', 'low', '\\n', 'Any w', 'a', 'y ', 'th', 'e ', 'w', 'in', 'd ', 'b', 'low', 's do', 'es', \"n't \", 'rea', 'll', 'y ', 'm', 'a', 'tt', 'er', ' to', ' me, ', 't', 'o me\\n', '\\nMama, ', 'just ', 'k', 'ill', 'e', 'd', ' a', ' m', 'an', '\\n', 'P', 'ut ', 'a ', 'gun', ' again', 's', 't ', 'his ', 'h', 'ead', ', ', 'p', 'u', 'll', 'e', 'd ', 'm', 'y t', 'ri', 'g', 'g', 'er', ', no', 'w ', 'h', \"e's \", 'd', 'ead', '\\nMama, ', 'life ', 'ha', 'd ', 'just ', 'be', 'gun', '\\n', 'But ', 'no', 'w ', \"I've go\", 'n', 'e ', 'and', ' ', 'th', 'row', 'n', ' ', 'it ', 'a', 'll', ' a', 'w', 'a', 'y\\n', 'Mama, ', 'ooh, ', 'di', 'd', \"n't \", 'm', 'ea', 'n', ' to', ' ma', 'k', 'e ', 'you ', 'c', 'r', 'y\\n', 'I', 'f ', \"I'm \", 'not ', 'ba', 'ck', ' again', ' ', 'th', 'i', 's ', 'tim', 'e ', 't', 'om', 'or', 'row', '\\n', 'C', 'ar', 'ry on', ', ', 'ca', 'r', 'ry on', ' a', 's ', 'i', 'f ', 'no', 'th', 'ing', ' rea', 'll', 'y ', 'm', 'a', 'tt', 'er', 's\\n', '\\nT', 'oo', ' ', 'l', 'a', 't', 'e, ', 'm', 'y t', 'ime ', 'has ', 'com', 'e\\nS', 'en', 'd', 's ', 's', 'hi', 'ver', 's do', 'w', 'n', ' m', 'y', ' s', 'p', 'in', 'e, ', 'bod', 'y', \"'s \", 'ac', 'h', 'ing', ' a', 'll ', 'th', 'e ', 'tim', 'e\\n', 'G', 'oo', 'd', 'b', 'y', 'e, ', 'ever', 'y', 'bod', 'y, ', \"I've go\", 't ', 'to ', 'go\\n', 'G', 'o', 'tta ', 'leave ', 'you', ' a', 'll ', 'be', 'h', 'in', 'd ', 'and', ' ', 'f', 'ac', 'e ', 'th', 'e ', 't', 'r', 'u', 'th', '\\nMama, ', 'oo', 'h', ' ', '(', 'Any w', 'a', 'y ', 'th', 'e ', 'w', 'in', 'd ', 'b', 'low', 's', ')\\n', 'I ', 'do', \"n't \", 'w', 'an', 'n', 'a ', 'die\\n', 'I s', 'om', 'e', 'tim', 'es ', 'wi', 's', 'h', ' ', \"I'\", 'd ', 'never', ' ', 'be', 'en ', 'b', 'or', 'n', ' a', 't ', 'a', 'll', '\\nS', 'ee ', 'up', 'com', 'ing', ' ', 'ro', 'c', 'k ', 's', 'h', 'o', 'w', 's\\n', 'G', 'et ', 'ti', 'ck', 'e', 't', 's ', 'f', 'or ', 'your ', 'f', 'a', 'v', 'or', 'it', 'e ', 'ar', 'ti', 'st', 's\\n', 'Y', 'ou', ' m', 'i', 'ght ', 'a', 'l', 's', 'o ', 'li', 'k', 'e\\nSo ', 'Lon', 'g', ', ', 'Lon', 'do', 'n', '\\nTay', 'lo', 'r', ' ', 'S', 'wi', 'f', 't', '\\n', 'But ', 'D', 'a', 'd', 'd', 'y ', 'I ', 'L', 'o', 've ', 'H', 'i', 'm', '\\nTay', 'lo', 'r', ' ', 'S', 'wi', 'f', 't', '\\n', 'l', 'om', 'l', '\\nTay', 'lo', 'r', ' ', 'S', 'wi', 'f', 't', '\\n', '[', 'G', 'u', 'it', 'ar', ' ', 'S', 'o', 'lo', ']', '\\n\\n', '\\n', 'I s', 'ee ', 'a ', 'little ', 's', 'il', 'h', 'ou', 'e', 'tt', 'o ', 'o', 'f', ' a', ' m', 'an', '\\nS', 'ca', 'r', 'am', 'ou', 'c', 'h', 'e, ', 'S', 'ca', 'r', 'am', 'ou', 'c', 'h', 'e, ', 'w', 'ill', ' ', 'you ', 'do', ' ', 'th', 'e ', 'F', 'and', 'an', 'go', '\\nT', 'h', 'un', 'd', 'er', 'bo', 'l', 't ', 'and', ' ', 'li', 'ght', 'n', 'ing', ', ', 'ver', 'y, ', 'ver', 'y ', 'fr', 'i', 'ght', 'en', 'ing', ' me\\n', '(Galileo) Galileo, ', '(Galileo) Galileo, ', 'Galile', 'o ', 'F', 'i', 'g', 'a', 'ro', ' ma', 'g', 'n', 'i', 'f', 'i', 'c', 'o ', '(O', 'h', '-oh-oh', '-oh', ')\\n', 'But ', \"I'm just a poor bo\", 'y, ', 'no', 'bod', 'y ', 'lo', 'v', 'es ', 'm', 'e\\n', 'H', \"e's \", 'just a poor bo', 'y ', 'from', ' a', ' ', 'p', 'o', 'or ', 'f', 'am', 'il', 'y\\n', 'S', 'p', 'ar', 'e ', 'him ', 'his ', 'life ', 'from', ' ', 'th', 'i', 's ', 'm', 'on', 'st', 'ro', 's', 'it', 'y\\n', 'E', 'as', 'y ', 'come, easy go, ', 'w', 'ill', ' ', 'you ', 'let me go\\n', 'Bismilla', 'h', ', no', ', ', 'we ', 'w', 'ill', ' ', 'not let you go\\n(Let ', 'him ', 'go) ', 'Bismillah, ', 'we ', 'w', 'ill', ' ', 'not let you go\\n(Let ', 'him ', 'go) ', 'Bismillah, ', 'we ', 'w', 'ill', ' ', 'not let you go\\n(Let ', 'me go) W', 'ill', ' ', 'not let you go\\n(Let ', 'me go) W', 'ill', ' ', 'not let you go\\n(', 'N', 'ever', ', never, never', ', never', ' ', 'let me ', 'go) ', 'A', 'h', '\\n', 'No', ', no, no, no, no', ', no, no', '\\n(O', 'h, ', 'mam', 'm', 'a ', 'm', 'i', 'a, ', 'mam', 'm', 'a ', 'm', 'i', 'a', ') ', 'Mam', 'm', 'a ', 'm', 'i', 'a, ', 'let me go\\n', 'B', 'ee', 'l', 'z', 'e', 'b', 'u', 'b', ' ', 'has ', 'a ', 'd', 'e', 'v', 'il', ' ', 'p', 'ut ', 'as', 'i', 'd', 'e ', 'f', 'or ', 'm', 'e, ', 'f', 'or ', 'm', 'e, ', 'f', 'or ', 'm', 'e\\n', '\\n', '\\nS', 'o ', 'you ', 'th', 'in', 'k ', 'you ', 'can', ' s', 't', 'one ', 'me ', 'and', ' s', 'p', 'it ', 'in', ' my ', 'ey', 'e\\nSo ', 'you ', 'th', 'in', 'k ', 'you ', 'can', ' ', 'lo', 've ', 'me ', 'and', ' ', 'leave ', 'me ', 'to ', 'die\\n', 'O', 'h, ', 'bab', 'y, ', 'can', \"'t \", 'do', ' ', 'th', 'i', 's ', 't', 'o', ' me, ', 'bab', 'y\\n', 'J', 'ust ', 'gotta get ', 'ou', 't', ', ', 'just ', 'gotta get ', 'ri', 'ght ', 'ou', 'tta ', 'h', 'er', 'e\\n', '\\n(O', 'oh', ')\\n', '(O', 'o', 'h, ', 'yea', 'h, ', 'ooh, ', 'yea', 'h', ')\\n', 'No', 'th', 'ing', ' rea', 'll', 'y ', 'm', 'a', 'tt', 'er', 's', ', ', 'an', 'y', 'one ', 'can', ' s', 'ee', '\\n', 'No', 'th', 'ing', ' rea', 'll', 'y ', 'm', 'a', 'tt', 'er', 's\\n', 'No', 'th', 'ing', ' rea', 'll', 'y ', 'm', 'a', 'tt', 'er', 's ', 't', 'o me\\n', 'Any w', 'a', 'y ', 'th', 'e ', 'w', 'in', 'd ', 'b', 'low', 's']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'gh' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m toks \u001b[39m=\u001b[39m tokenize_with_bpe(text\u001b[39m=\u001b[39mpoem_text, merges\u001b[39m=\u001b[39mmerges)\n\u001b[1;32m     67\u001b[0m \u001b[39mprint\u001b[39m(toks)\n\u001b[0;32m---> 68\u001b[0m tok_idx \u001b[39m=\u001b[39m [tokens\u001b[39m.\u001b[39;49mindex(i) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m toks]\n\u001b[1;32m     69\u001b[0m \u001b[39m# print(\"Final Tokens:\", tokens)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m# print(\"Final Vocabulary:\", vocab)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[61], line 68\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m toks \u001b[39m=\u001b[39m tokenize_with_bpe(text\u001b[39m=\u001b[39mpoem_text, merges\u001b[39m=\u001b[39mmerges)\n\u001b[1;32m     67\u001b[0m \u001b[39mprint\u001b[39m(toks)\n\u001b[0;32m---> 68\u001b[0m tok_idx \u001b[39m=\u001b[39m [tokens\u001b[39m.\u001b[39mindex(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m toks]\n\u001b[1;32m     69\u001b[0m \u001b[39m# print(\"Final Tokens:\", tokens)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m# print(\"Final Vocabulary:\", vocab)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: 'gh' is not in list"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def get_pair_frequencies(tokens):\n",
    "    \"\"\"Compute frequencies of adjacent token pairs.\"\"\"\n",
    "    pairs = [tuple(tokens[i:i+2]) for i in range(len(tokens) - 1)]\n",
    "    return Counter(pairs)\n",
    "\n",
    "def merge_pair(tokens, pair, new_token):\n",
    "    \"\"\"Merge the most frequent pair in the token list.\"\"\"\n",
    "    merged_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i < len(tokens) - 1 and (tokens[i], tokens[i+1]) == pair:\n",
    "            merged_tokens.append(new_token)\n",
    "            i += 2  # Skip next token as it's merged\n",
    "        else:\n",
    "            merged_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "    return merged_tokens\n",
    "\n",
    "def byte_pair_encoding(text, num_merges):\n",
    "    \"\"\"Train BPE and return tokens, vocab, and learned merges.\"\"\"\n",
    "    tokens = list(text)  # Initialize as character tokens\n",
    "    vocab = set(tokens)  # Initial vocabulary\n",
    "    merges = {}  # Store merge rules\n",
    "\n",
    "    for _ in range(num_merges):\n",
    "        pair_freqs = get_pair_frequencies(tokens)\n",
    "        if not pair_freqs:\n",
    "            break\n",
    "        most_frequent_pair = max(pair_freqs, key=pair_freqs.get)\n",
    "\n",
    "        new_token = \"\".join(most_frequent_pair)  # Merge pair into a new token\n",
    "        vocab.add(new_token)  # Add new token to vocabulary\n",
    "        merges[most_frequent_pair] = new_token  # Store merge step\n",
    "\n",
    "        tokens = merge_pair(tokens, most_frequent_pair, new_token)\n",
    "\n",
    "    return tokens, vocab, merges\n",
    "\n",
    "def tokenize_with_bpe(text, merges):\n",
    "    \"\"\"Tokenizes text using learned BPE merges.\"\"\"\n",
    "    tokens = list(text)  # Start with character-level tokens\n",
    "\n",
    "    # Apply stored merges in order\n",
    "    while True:\n",
    "        pair_freqs = get_pair_frequencies(tokens)\n",
    "        if not pair_freqs:\n",
    "            break\n",
    "        \n",
    "        merge_candidates = [(pair, merges[pair]) for pair in pair_freqs if pair in merges]\n",
    "        if not merge_candidates:\n",
    "            break\n",
    "\n",
    "        # Apply the first merge in stored order\n",
    "        pair_to_merge, new_token = merge_candidates[0]\n",
    "        tokens = merge_pair(tokens, pair_to_merge, new_token)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Example usage\n",
    "text = poem_text\n",
    "num_merges = 300\n",
    "tokens, vocab, merges = byte_pair_encoding(text, num_merges)\n",
    "toks = tokenize_with_bpe(text=poem_text, merges=merges)\n",
    "print(toks)\n",
    "tok_idx = [tokens.index(i) for i in toks]\n",
    "# print(\"Final Tokens:\", tokens)\n",
    "# print(\"Final Vocabulary:\", vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is this the real life Is this just fantasy\\nCaught in',\n",
       " ' ',\n",
       " 'a ',\n",
       " 'l',\n",
       " 'and',\n",
       " 's',\n",
       " 'li',\n",
       " 'd',\n",
       " 'e, ',\n",
       " 'no',\n",
       " ' ',\n",
       " 'es',\n",
       " 'ca',\n",
       " 'p',\n",
       " 'e ',\n",
       " 'from',\n",
       " ' rea',\n",
       " 'li',\n",
       " 't',\n",
       " 'y\\n',\n",
       " 'O',\n",
       " 'p',\n",
       " 'en ',\n",
       " 'your ',\n",
       " 'ey',\n",
       " 'es',\n",
       " ', ',\n",
       " 'lo',\n",
       " 'o',\n",
       " 'k ',\n",
       " 'up',\n",
       " ' to',\n",
       " ' the ',\n",
       " 's',\n",
       " 'k',\n",
       " 'i',\n",
       " 'es ',\n",
       " 'and s',\n",
       " 'ee\\n',\n",
       " \"I'm just a poor bo\",\n",
       " 'y, ',\n",
       " 'I ',\n",
       " 'n',\n",
       " 'ee',\n",
       " 'd ',\n",
       " 'no',\n",
       " ' s',\n",
       " 'y',\n",
       " 'm',\n",
       " 'p',\n",
       " 'a',\n",
       " 'th',\n",
       " 'y\\n',\n",
       " 'B',\n",
       " 'e',\n",
       " 'ca',\n",
       " 'us',\n",
       " 'e ',\n",
       " \"I'm \",\n",
       " 'easy ',\n",
       " 'come, easy go, ',\n",
       " 'little ',\n",
       " 'hi',\n",
       " 'g',\n",
       " 'h, ',\n",
       " 'little ',\n",
       " 'low',\n",
       " '\\n',\n",
       " 'Any way the wind blow',\n",
       " 's do',\n",
       " 'es',\n",
       " \"n't \",\n",
       " 'rea',\n",
       " 'lly matter',\n",
       " ' to',\n",
       " ' me, ',\n",
       " 't',\n",
       " 'o me\\n',\n",
       " '\\nMama, ',\n",
       " 'just ',\n",
       " 'k',\n",
       " 'ill',\n",
       " 'e',\n",
       " 'd ',\n",
       " 'a m',\n",
       " 'an',\n",
       " '\\n',\n",
       " 'P',\n",
       " 'ut ',\n",
       " 'a ',\n",
       " 'gun',\n",
       " ' again',\n",
       " 's',\n",
       " 't ',\n",
       " 'his ',\n",
       " 'h',\n",
       " 'ead',\n",
       " ', ',\n",
       " 'p',\n",
       " 'u',\n",
       " 'll',\n",
       " 'e',\n",
       " 'd',\n",
       " ' m',\n",
       " 'y t',\n",
       " 'ri',\n",
       " 'g',\n",
       " 'g',\n",
       " 'er',\n",
       " ', no',\n",
       " 'w ',\n",
       " 'h',\n",
       " \"e's \",\n",
       " 'd',\n",
       " 'ead',\n",
       " '\\nMama, ',\n",
       " 'life ',\n",
       " 'ha',\n",
       " 'd ',\n",
       " 'just ',\n",
       " 'be',\n",
       " 'gun',\n",
       " '\\n',\n",
       " 'But ',\n",
       " 'no',\n",
       " 'w ',\n",
       " \"I've go\",\n",
       " 'n',\n",
       " 'e ',\n",
       " 'and',\n",
       " ' th',\n",
       " 'row',\n",
       " 'n',\n",
       " ' ',\n",
       " 'it ',\n",
       " 'all ',\n",
       " 'a',\n",
       " 'w',\n",
       " 'a',\n",
       " 'y\\n',\n",
       " 'Mama, ',\n",
       " 'ooh, ',\n",
       " 'di',\n",
       " 'd',\n",
       " \"n't \",\n",
       " 'm',\n",
       " 'e',\n",
       " 'an',\n",
       " ' to',\n",
       " ' ma',\n",
       " 'k',\n",
       " 'e ',\n",
       " 'you ',\n",
       " 'c',\n",
       " 'r',\n",
       " 'y\\n',\n",
       " 'I',\n",
       " 'f ',\n",
       " \"I'm \",\n",
       " 'not ',\n",
       " 'ba',\n",
       " 'ck',\n",
       " ' again',\n",
       " ' this t',\n",
       " 'ime ',\n",
       " 't',\n",
       " 'om',\n",
       " 'or',\n",
       " 'row',\n",
       " '\\n',\n",
       " 'C',\n",
       " 'ar',\n",
       " 'ry on',\n",
       " ', ',\n",
       " 'car',\n",
       " 'ry on',\n",
       " ' a',\n",
       " 's ',\n",
       " 'i',\n",
       " 'f ',\n",
       " 'no',\n",
       " 'thing really matter',\n",
       " 's\\n',\n",
       " '\\nT',\n",
       " 'o',\n",
       " 'o ',\n",
       " 'l',\n",
       " 'a',\n",
       " 't',\n",
       " 'e, ',\n",
       " 'm',\n",
       " 'y t',\n",
       " 'ime ',\n",
       " 'has ',\n",
       " 'com',\n",
       " 'e\\nS',\n",
       " 'en',\n",
       " 'd',\n",
       " 's ',\n",
       " 's',\n",
       " 'hi',\n",
       " 'ver',\n",
       " 's do',\n",
       " 'w',\n",
       " 'n',\n",
       " ' my ',\n",
       " 's',\n",
       " 'p',\n",
       " 'in',\n",
       " 'e, ',\n",
       " 'bod',\n",
       " 'y',\n",
       " \"'s \",\n",
       " 'ac',\n",
       " 'hing',\n",
       " ' a',\n",
       " 'll',\n",
       " ' the ',\n",
       " 'tim',\n",
       " 'e\\n',\n",
       " 'G',\n",
       " 'oo',\n",
       " 'd',\n",
       " 'b',\n",
       " 'y',\n",
       " 'e, ',\n",
       " 'ever',\n",
       " 'y',\n",
       " 'bod',\n",
       " 'y, ',\n",
       " \"I've go\",\n",
       " 't ',\n",
       " 'to ',\n",
       " 'go\\n',\n",
       " 'G',\n",
       " 'o',\n",
       " 'tta ',\n",
       " 'leave ',\n",
       " 'you ',\n",
       " 'all ',\n",
       " 'be',\n",
       " 'hin',\n",
       " 'd ',\n",
       " 'and ',\n",
       " 'f',\n",
       " 'ac',\n",
       " 'e ',\n",
       " 'th',\n",
       " 'e ',\n",
       " 't',\n",
       " 'r',\n",
       " 'u',\n",
       " 'th',\n",
       " '\\nMama, ',\n",
       " 'o',\n",
       " 'oh',\n",
       " ' ',\n",
       " '(',\n",
       " 'Any way the wind blows',\n",
       " ')\\n',\n",
       " 'I ',\n",
       " 'don',\n",
       " \"'t \",\n",
       " 'w',\n",
       " 'an',\n",
       " 'n',\n",
       " 'a ',\n",
       " 'die\\n',\n",
       " 'I s',\n",
       " 'om',\n",
       " 'e',\n",
       " 'tim',\n",
       " 'es ',\n",
       " 'wi',\n",
       " 's',\n",
       " 'h',\n",
       " ' ',\n",
       " \"I'\",\n",
       " 'd ',\n",
       " 'never',\n",
       " ' ',\n",
       " 'be',\n",
       " 'en ',\n",
       " 'b',\n",
       " 'or',\n",
       " 'n',\n",
       " ' a',\n",
       " 't ',\n",
       " 'a',\n",
       " 'll',\n",
       " '\\nS',\n",
       " 'ee ',\n",
       " 'up',\n",
       " 'com',\n",
       " 'ing',\n",
       " ' ',\n",
       " 'ro',\n",
       " 'ck',\n",
       " ' s',\n",
       " 'h',\n",
       " 'o',\n",
       " 'w',\n",
       " 's\\n',\n",
       " 'G',\n",
       " 'et ',\n",
       " 'ti',\n",
       " 'ck',\n",
       " 'e',\n",
       " 't',\n",
       " 's ',\n",
       " 'f',\n",
       " 'or ',\n",
       " 'your ',\n",
       " 'f',\n",
       " 'a',\n",
       " 'v',\n",
       " 'or',\n",
       " 'it',\n",
       " 'e ',\n",
       " 'ar',\n",
       " 'ti',\n",
       " 'st',\n",
       " 's\\n',\n",
       " 'Y',\n",
       " 'ou',\n",
       " ' m',\n",
       " 'i',\n",
       " 'ght ',\n",
       " 'a',\n",
       " 'l',\n",
       " 's',\n",
       " 'o ',\n",
       " 'li',\n",
       " 'k',\n",
       " 'e\\nSo ',\n",
       " 'Lon',\n",
       " 'g',\n",
       " ', ',\n",
       " 'Lon',\n",
       " 'don',\n",
       " '\\nTaylor Swift\\n',\n",
       " 'But ',\n",
       " 'D',\n",
       " 'a',\n",
       " 'd',\n",
       " 'd',\n",
       " 'y ',\n",
       " 'I ',\n",
       " 'L',\n",
       " 'o',\n",
       " 've ',\n",
       " 'H',\n",
       " 'i',\n",
       " 'm',\n",
       " '\\nTaylor Swift\\n',\n",
       " 'l',\n",
       " 'om',\n",
       " 'l',\n",
       " '\\nTaylor Swift\\n',\n",
       " '[',\n",
       " 'G',\n",
       " 'u',\n",
       " 'it',\n",
       " 'ar',\n",
       " ' ',\n",
       " 'S',\n",
       " 'o',\n",
       " 'lo',\n",
       " ']',\n",
       " '\\n\\n',\n",
       " '\\n',\n",
       " 'I s',\n",
       " 'ee ',\n",
       " 'a ',\n",
       " 'little ',\n",
       " 's',\n",
       " 'il',\n",
       " 'h',\n",
       " 'ou',\n",
       " 'e',\n",
       " 'tt',\n",
       " 'o ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' a',\n",
       " ' m',\n",
       " 'an',\n",
       " '\\nS',\n",
       " 'caramouche, ',\n",
       " 'S',\n",
       " 'caramouche, ',\n",
       " 'will you ',\n",
       " 'do',\n",
       " ' the ',\n",
       " 'F',\n",
       " 'and',\n",
       " 'an',\n",
       " 'go\\n',\n",
       " 'T',\n",
       " 'h',\n",
       " 'un',\n",
       " 'd',\n",
       " 'er',\n",
       " 'bo',\n",
       " 'l',\n",
       " 't ',\n",
       " 'and ',\n",
       " 'li',\n",
       " 'ght',\n",
       " 'n',\n",
       " 'ing',\n",
       " ', ',\n",
       " 'ver',\n",
       " 'y, ',\n",
       " 'ver',\n",
       " 'y ',\n",
       " 'fr',\n",
       " 'i',\n",
       " 'ght',\n",
       " 'en',\n",
       " 'ing',\n",
       " ' me\\n',\n",
       " '(Galileo) Galileo, ',\n",
       " '(Galileo) Galileo, ',\n",
       " 'Galile',\n",
       " 'o ',\n",
       " 'F',\n",
       " 'i',\n",
       " 'g',\n",
       " 'ar',\n",
       " 'o',\n",
       " ' ma',\n",
       " 'g',\n",
       " 'n',\n",
       " 'i',\n",
       " 'f',\n",
       " 'i',\n",
       " 'c',\n",
       " 'o ',\n",
       " '(O',\n",
       " 'h',\n",
       " '-oh-oh',\n",
       " '-oh',\n",
       " ')\\n',\n",
       " 'But ',\n",
       " \"I'm just a poor bo\",\n",
       " 'y',\n",
       " ', no',\n",
       " 'bod',\n",
       " 'y ',\n",
       " 'lo',\n",
       " 'v',\n",
       " 'es',\n",
       " ' me\\n',\n",
       " 'H',\n",
       " \"e's \",\n",
       " 'just a poor bo',\n",
       " 'y ',\n",
       " 'from',\n",
       " ' ',\n",
       " 'a poor ',\n",
       " 'f',\n",
       " 'am',\n",
       " 'il',\n",
       " 'y\\n',\n",
       " 'S',\n",
       " 'p',\n",
       " 'ar',\n",
       " 'e ',\n",
       " 'him ',\n",
       " 'his ',\n",
       " 'life ',\n",
       " 'from',\n",
       " ' thi',\n",
       " 's',\n",
       " ' m',\n",
       " 'on',\n",
       " 'st',\n",
       " 'ro',\n",
       " 's',\n",
       " 'it',\n",
       " 'y\\n',\n",
       " 'E',\n",
       " 'a',\n",
       " 'sy ',\n",
       " 'come, easy go, ',\n",
       " 'will you ',\n",
       " 'let me go\\n',\n",
       " 'Bismillah, ',\n",
       " 'no',\n",
       " ', ',\n",
       " 'we will not let you go\\n(Let him go) Bismillah, ',\n",
       " 'we will not let you go\\n(Let him go) Bismillah, ',\n",
       " 'we will not let you go\\n(Let ',\n",
       " 'me go) Will ',\n",
       " 'not let you go\\n(Let ',\n",
       " 'me go) Will ',\n",
       " 'not let you go\\n(',\n",
       " 'N',\n",
       " 'ever',\n",
       " ', never, never',\n",
       " ', never',\n",
       " ' ',\n",
       " 'let me ',\n",
       " 'go) ',\n",
       " 'A',\n",
       " 'h',\n",
       " '\\n',\n",
       " 'No',\n",
       " ', no, no, no, no',\n",
       " ', no, no',\n",
       " '\\n(O',\n",
       " 'h, ',\n",
       " 'mamma mi',\n",
       " 'a, ',\n",
       " 'mamma mi',\n",
       " 'a',\n",
       " ') ',\n",
       " 'Mam',\n",
       " 'ma mi',\n",
       " 'a, ',\n",
       " 'let me go\\n',\n",
       " 'B',\n",
       " 'ee',\n",
       " 'l',\n",
       " 'z',\n",
       " 'e',\n",
       " 'b',\n",
       " 'u',\n",
       " 'b',\n",
       " ' ',\n",
       " 'has ',\n",
       " 'a ',\n",
       " 'd',\n",
       " 'e',\n",
       " 'v',\n",
       " 'il',\n",
       " ' ',\n",
       " 'p',\n",
       " 'ut ',\n",
       " 'as',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e ',\n",
       " 'for me, ',\n",
       " 'for me, ',\n",
       " 'for',\n",
       " ' me\\n',\n",
       " '\\n',\n",
       " '\\nS',\n",
       " 'o ',\n",
       " 'you think you can',\n",
       " ' s',\n",
       " 't',\n",
       " 'one ',\n",
       " 'me ',\n",
       " 'and s',\n",
       " 'p',\n",
       " 'it ',\n",
       " 'in',\n",
       " ' my ',\n",
       " 'ey',\n",
       " 'e\\nSo ',\n",
       " 'you think you can',\n",
       " ' ',\n",
       " 'lo',\n",
       " 've ',\n",
       " 'me ',\n",
       " 'and ',\n",
       " 'leave ',\n",
       " 'me ',\n",
       " 'to ',\n",
       " 'die\\n',\n",
       " 'O',\n",
       " 'h, ',\n",
       " 'bab',\n",
       " 'y, ',\n",
       " 'can',\n",
       " \"'t \",\n",
       " 'do',\n",
       " ' this t',\n",
       " 'o',\n",
       " ' me, ',\n",
       " 'bab',\n",
       " 'y\\n',\n",
       " 'J',\n",
       " 'ust ',\n",
       " 'gotta get ',\n",
       " 'ou',\n",
       " 't',\n",
       " ', ',\n",
       " 'just ',\n",
       " 'gotta get ',\n",
       " 'ri',\n",
       " 'ght ',\n",
       " 'ou',\n",
       " 'tta ',\n",
       " 'h',\n",
       " 'er',\n",
       " 'e\\n',\n",
       " '\\n(O',\n",
       " 'oh',\n",
       " ')\\n',\n",
       " '(O',\n",
       " 'o',\n",
       " 'h, ',\n",
       " 'yea',\n",
       " 'h, ',\n",
       " 'ooh, ',\n",
       " 'yea',\n",
       " 'h',\n",
       " ')\\n',\n",
       " 'Nothing really matter',\n",
       " 's',\n",
       " ', ',\n",
       " 'an',\n",
       " 'y',\n",
       " 'one ',\n",
       " 'can',\n",
       " ' s',\n",
       " 'ee\\n',\n",
       " 'Nothing really matter',\n",
       " 's\\n',\n",
       " 'Nothing really matter',\n",
       " 's t',\n",
       " 'o me\\n',\n",
       " 'Any way the wind blows']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>​​rockstar</td>\n",
       "      <td>beerbongs &amp; bentleys</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017-09-15</td>\n",
       "      <td>post malone hahahahaha tank god ayy ayy   post...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>White Iverson</td>\n",
       "      <td>Stoney (Deluxe)</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>double ot i'm a new three   saucin' saucin' i'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>Stoney (Deluxe)</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>post malone mmmmm yeah yeah mmmmm yeah hey   p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Psycho</td>\n",
       "      <td>beerbongs &amp; bentleys</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2018-02-23</td>\n",
       "      <td>post malone damn my ap goin' psycho lil' mama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>I Fall Apart</td>\n",
       "      <td>Stoney (Deluxe)</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>ooh i fall apart ooh yeah mmm yeah   she told ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Lithium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>i'm so happy 'cause today i found my friends t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Something in the Way</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>verse underneath the  tarp has sprung a leak a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>In Bloom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>sell the kids for food weather changes moods s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Territorial Pissings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>when i was an alien cultures weren't opinions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>verse won't you believe it it's just my luck w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       Artist                 Title                 Album  \\\n",
       "0             0  Post Malone            ​​rockstar  beerbongs & bentleys   \n",
       "1             1  Post Malone         White Iverson       Stoney (Deluxe)   \n",
       "2             2  Post Malone       Congratulations       Stoney (Deluxe)   \n",
       "3             3  Post Malone                Psycho  beerbongs & bentleys   \n",
       "4             4  Post Malone          I Fall Apart       Stoney (Deluxe)   \n",
       "..          ...          ...                   ...                   ...   \n",
       "143         143  Post Malone               Lithium                   NaN   \n",
       "144         144  Post Malone  Something in the Way                   NaN   \n",
       "145         145  Post Malone              In Bloom                   NaN   \n",
       "146         146  Post Malone  Territorial Pissings                   NaN   \n",
       "147         147  Post Malone                School                   NaN   \n",
       "\n",
       "       Year        Date                                              Lyric  \n",
       "0    2017.0  2017-09-15  post malone hahahahaha tank god ayy ayy   post...  \n",
       "1    2015.0  2015-02-04  double ot i'm a new three   saucin' saucin' i'...  \n",
       "2    2016.0  2016-11-04  post malone mmmmm yeah yeah mmmmm yeah hey   p...  \n",
       "3    2018.0  2018-02-23  post malone damn my ap goin' psycho lil' mama ...  \n",
       "4    2016.0  2016-12-09  ooh i fall apart ooh yeah mmm yeah   she told ...  \n",
       "..      ...         ...                                                ...  \n",
       "143  2020.0  2020-04-24  i'm so happy 'cause today i found my friends t...  \n",
       "144  2020.0  2020-04-24  verse underneath the  tarp has sprung a leak a...  \n",
       "145  2020.0  2020-04-24  sell the kids for food weather changes moods s...  \n",
       "146  2020.0  2020-04-24  when i was an alien cultures weren't opinions ...  \n",
       "147  2020.0  2020-04-24  verse won't you believe it it's just my luck w...  \n",
       "\n",
       "[148 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/hamza.mahmood/Developer/deep_learning_course/LSTM-from-Scratch-using-Numpy/data/5/csv/PostMalone.csv\")\n",
    "# combined_string = \"\\n\".join(df[\"Lyric\"].astype(str))\n",
    "# print(combined_string)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/hamza.mahmood/Developer/deep_learning_course/LSTM-from-Scratch-using-Numpy/data/postmalone.txt\", \"w\") as f:\n",
    "    f.write(combined_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \n",
      "\n",
      "32  \n",
      "40 (\n",
      "65 A\n",
      "66 B\n",
      "67 C\n",
      "68 D\n",
      "69 E\n",
      "70 F\n",
      "71 G\n",
      "72 H\n",
      "73 I\n",
      "74 J\n",
      "76 L\n",
      "78 N\n",
      "79 O\n",
      "80 P\n",
      "83 S\n",
      "84 T\n",
      "87 W\n",
      "89 Y\n",
      "91 [\n",
      "93 ]\n",
      "97 a\n",
      "98 b\n",
      "99 c\n",
      "100 d\n",
      "101 e\n",
      "102 f\n",
      "103 g\n",
      "104 h\n",
      "105 i\n",
      "107 k\n",
      "108 l\n",
      "109 m\n",
      "110 n\n",
      "111 o\n",
      "112 p\n",
      "114 r\n",
      "115 s\n",
      "116 t\n",
      "117 u\n",
      "118 v\n",
      "119 w\n",
      "121 y\n",
      "122 z\n",
      "256 , \n",
      "257 t \n",
      "258 e \n",
      "259  m\n",
      "260  t\n",
      "261 ou\n",
      "262 ll\n",
      "263 hi\n",
      "264 go\n",
      "265 an\n",
      "266 no\n",
      "267 er\n",
      "268 ea\n",
      "269 li\n",
      "270 s \n",
      "271 you\n",
      "272 y \n",
      "273 et \n",
      "274 e\n",
      "\n",
      "275 or\n",
      "276 a \n",
      "277 d \n",
      "278 tt\n",
      "279 e, \n",
      "280 wi\n",
      "281 you \n",
      "282 om\n",
      "283 h, \n",
      "284 am\n",
      "285 me \n",
      "286 o \n",
      "287 us\n",
      "288 ll \n",
      "289 on\n",
      "290 ver\n",
      "291 go\n",
      "\n",
      "292  th\n",
      "293 ust \n",
      "294 y\n",
      "\n",
      "295 in\n",
      "296 lo\n",
      "297 or \n",
      "298 , no\n",
      "299 ar\n",
      "300 hin\n",
      "301 ) \n",
      "303  the \n",
      "304 rea\n",
      "305 just \n",
      "306 I'\n",
      "308 bo\n",
      "309  ma\n",
      "310  s\n",
      "312 a, \n",
      "313  a\n",
      "314 ve \n",
      "315 not \n",
      "316 ever\n",
      "317 s t\n",
      "318 gh\n",
      "319  rea\n",
      "320 and \n",
      "324 lly matter\n",
      "325  me\n",
      "\n",
      "326 Mam\n",
      "327 ut \n",
      "328 hing\n",
      "329 oh\n",
      "330 will \n",
      "334 Galile\n",
      "338 not let you go\n",
      "(\n",
      "339 go) \n",
      "340 , no, no\n",
      "341 es\n",
      "342 fr\n",
      "343 en\n",
      "344 I'm \n",
      "347 a poor \n",
      "348 y, \n",
      "349 sy \n",
      "350 com\n",
      "351 low\n",
      "352 do\n",
      "353 't \n",
      "354  me, \n",
      "355 Mama, \n",
      "356 ill\n",
      "357 a m\n",
      "358 ro\n",
      "361 thing really matter\n",
      "362 s\n",
      "\n",
      "363 \n",
      "T\n",
      "364 ti\n",
      "365 tta \n",
      "366 )\n",
      "\n",
      "367 never\n",
      "368 Galileo\n",
      "369 (O\n",
      "371 not let you go\n",
      "(Let \n",
      "372 No\n",
      "373 can\n",
      "375 life \n",
      "376 his \n",
      "377 ght \n",
      "378 and\n",
      "379 from\n",
      "380 k \n",
      "381  to\n",
      "383 just a poor bo\n",
      "384 I \n",
      "385 th\n",
      "386 easy \n",
      "389 little \n",
      "399 Any way the wind blow\n",
      "400 \n",
      "Mama, \n",
      "401 un\n",
      "402 's \n",
      "403 ha\n",
      "404 be\n",
      "405 But \n",
      "406 oo\n",
      "407 di\n",
      "408 ba\n",
      "409 ck\n",
      "410  thi\n",
      "411 car\n",
      "412 e\n",
      "S\n",
      "413 bod\n",
      "414 \n",
      "S\n",
      "415 ing\n",
      "416 it\n",
      "424 \n",
      "Taylor Swift\n",
      "\n",
      "425 il\n",
      "426 -oh\n",
      "427 him \n",
      "428 let me \n",
      "434 Bismillah, \n",
      "437 we will not let you go\n",
      "(Let \n",
      "438 , never\n",
      "440 ma mi\n",
      "441 for\n",
      "442 Nothing really matter\n",
      "443 Is t\n",
      "444 as\n",
      "445 ca\n",
      "446 en \n",
      "448 your \n",
      "449 ey\n",
      "450 up\n",
      "451 es \n",
      "452 and s\n",
      "453 ee\n",
      "\n",
      "454 I'm just a poor bo\n",
      "455 ee\n"
     ]
    }
   ],
   "source": [
    "from src.basic import BasicTokenizer\n",
    "tokenizer = BasicTokenizer()\n",
    "text = poem_text\n",
    "tokenizer.train(text, 256 + 200) # 256 are the byte tokens, then do 3 merges\n",
    "tokens = tokenizer.encode(poem_text)\n",
    "# print(tokenizer.decode(tokens[5:10]))\n",
    "# print(len(tokens))\n",
    "\n",
    "for tok in set(tokens):\n",
    "    print(tok, tokenizer.decode([tok]))\n",
    "# tokenizer.save(\"toy\")\n",
    "# writes two files: toy.model (for loading) and toy.vocab (for viewing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10,\n",
       " 32,\n",
       " 40,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 76,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 83,\n",
       " 84,\n",
       " 87,\n",
       " 89,\n",
       " 91,\n",
       " 93,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 121,\n",
       " 122,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 334,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 389,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 434,\n",
       " 437,\n",
       " 438,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tokenizer.encode(poem_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "probabilities do not sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m vocab_size \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m      4\u001b[0m probs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.3\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.3\u001b[39m])\u001b[39m/\u001b[39m\u001b[39m0.7\u001b[39m  \u001b[39m# Probabilities for each token\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m next_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(\u001b[39mrange\u001b[39;49m(vocab_size), p\u001b[39m=\u001b[39;49mprobs\u001b[39m.\u001b[39;49mravel())\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mChosen index:\u001b[39m\u001b[39m\"\u001b[39m, next_idx)\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:994\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities do not sum to 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab_size = 5\n",
    "probs = np.array([0.1, 0.2, 0.3, 0.1, 0.3])/0.7  # Probabilities for each token\n",
    "\n",
    "next_idx = np.random.choice(range(vocab_size), p=probs.ravel())\n",
    "print(\"Chosen index:\", next_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
